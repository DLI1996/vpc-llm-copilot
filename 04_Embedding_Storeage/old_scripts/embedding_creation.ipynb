{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Embed\n",
    "\n",
    "First, we will create sample documents to be embedded using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"../06_Data/\"\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(folder_path, filename), 'r') as f:\n",
    "            content = f.read()\n",
    "            documents.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple announces the release of the iPad, a new device that is a combination of a laptop and a smartphone. The iPad is thinner and lighter than a laptop and has a touchscreen display. It can be used for browsing the web, email, viewing photos and videos, listening to music, and reading ebooks. The iPad also has a new app called iBooks, which allows users to purchase and read ebooks. The iPad will be available in both Wi-Fi and 3G models, with prices starting at $499. Accessories such as a dock, keyboard dock, and case are also available. The iPad will be available for purchase in 60 days.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use OpenAI to vectorize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "pinecone_key = os.getenv(\"PINECONE_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing API\n",
      "1536 dims returned!\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing API\")\n",
    "try:\n",
    "    print(f\"{len(get_embedding(documents[0]))} dims returned!\")\n",
    "except:\n",
    "    print(\"API Call Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "embeddings = [get_embedding(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload\n",
    "\n",
    "After creating the embeddings, we will publish these to a pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Set index name\n",
    "index_name = \"document-embeddings\"\n",
    "\n",
    "# Initialize pinecone session\n",
    "pinecone.init(api_key=pinecone_key, environment='gcp-starter')\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors: 1\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for uploading to pinecone\n",
    "vectors = [{'id': str(i), 'values': [float(value) for value in embeddings[i]]} for i in range(len(embeddings))]\n",
    "print(f\"Number of vectors: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload embeddings to pinecone\n",
    "index.upsert(vectors=vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have uploaded the origional embedded documents to the index. Below, we will add a few more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# New documents\n",
    "new_documents = [\n",
    "    \"New document text here\",\n",
    "    \"Another new document text here\",\n",
    "    \"Uniqueness is very important, I will use it to find this vector!\"\n",
    "    # ... more documents\n",
    "]\n",
    "\n",
    "# Vectorize the new documents\n",
    "new_X = vectorizer.transform(new_documents)  # Note: use transform, not fit_transform, to keep the same vocabulary\n",
    "\n",
    "# Convert to dense array\n",
    "new_embeddings = new_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Existing Pinecone Index\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the new data for uploading to Pinecone\n",
    "start_id = len(embeddings)\n",
    "new_vectors = [{'id': str(start_id + i), 'values': [float(value) for value in new_embeddings[i]]} for i in range(len(new_embeddings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_response = index.upsert(vectors=new_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare and Query\n",
    "\n",
    "We have uploaded even more vectors to the index. Now, we need to retrieve some of them that are similar to a sentence I will write below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize new sentence\n",
    "new_sentence = \"I am going to buy a new iphone!\"\n",
    "new_vector = get_embedding(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the new vector to a list of standard Python float values\n",
    "new_vector_list = [float(value) for value in new_vector]\n",
    "\n",
    "# Query Pinecone for the most similar vector(s)\n",
    "query_response = index.query(\n",
    "    top_k=2,\n",
    "    vector=new_vector_list,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0', 'score': 0.802503169, 'values': []}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_response['matches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the cosine similarity for the sentence I wrote and the one I wanted to find (the sentence with unique in it) is almost the highest at 0.7072.\n",
    "\n",
    "My query sentence: \"I want to find the unique vector, it is important!\"\n",
    "\n",
    "The sentences returned:\n",
    "1. The dog is lazy but the fox is quick\n",
    "2. Uniqueness is very important, I will use it to find this vector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "vector_db = Pinecone.from_existing_index(index_name=index_name, embedding=OpenAIEmbeddings(openai_api_key=openai.api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vector_db is often called an \"index\" in the documentation, then you use a \"retriever interface\" to access said index \n",
    "vector_db_retriever = vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define answer template\n",
    "demo_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "\n",
    "Pay attention to the tone of the question and use it to determine the technical familiarity of the user with the product, and then adjust your answer accordingly.\n",
    "\n",
    "If you do not know the answer, advise the user to seek help via king wencheng support.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer tailored to the technical familiarity of the user:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for prompt template\n",
    "prompt_for_chain = PromptTemplate(template = demo_template, input_variables = [\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an OpenAI LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\", openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the chatbot building part... it feels too simple, but I think this will be enough to get it to work\n",
    "# chain type can be anything, \"stuff\" seems to be the most basic\n",
    "# we use the retriever from earlier\n",
    "# chain argument will just be our prompt template from earlier\n",
    "assistant = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                        retriever = vector_db_retriever,\n",
    "                                        chain_type = \"stuff\",\n",
    "                                        chain_type_kwargs = {\"prompt\": prompt_for_chain})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry to hear that your iPad is not turning on. Here are a few troubleshooting steps you can try:\\n\\n1. Make sure your iPad is charged. Connect it to a power source using the charging cable and let it charge for at least 15 minutes. Then try turning it on again.\\n\\n2. If your iPad is still not turning on, try a hard reset. Press and hold both the Home button and the Power button at the same time for about 10 seconds until you see the Apple logo. Then release the buttons and wait for your iPad to restart.\\n\\n3. If the above steps don't work, it's possible that there may be a hardware issue with your iPad. I recommend contacting Apple Support or visiting an Apple Store for further assistance. They will be able to help you diagnose and fix the problem.\\n\\nIf you need further assistance, I recommend reaching out to King Wencheng support for additional help.\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actually giving the prompt, run this to talk to the assistant\n",
    "assistant.run(\"My IPad is not turning on, help!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
