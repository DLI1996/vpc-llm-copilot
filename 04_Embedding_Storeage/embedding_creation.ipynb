{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Embed\n",
    "\n",
    "First, we will create sample documents to be embedded using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"My dog is quick and can jump over fences\",\n",
    "    \"I love my dog\",\n",
    "    \"The dog is lazy but the fox is quick\",\n",
    "    \"Uniqueness can help us find vectors, I hope this works!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use sklearn to vectorize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "embeddings = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload\n",
    "\n",
    "After creating the embeddings, we will publish these to a pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nuke2\\Desktop\\NW Work\\Fall_02 Work\\LLM-Product-Assistant\\.venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "pinecone_key = os.getenv(\"PINECONE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine dimensionality of embeddings\n",
    "dimension = embeddings.shape[1]\n",
    "\n",
    "# Get index name\n",
    "index_name = \"document-embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pinecone session\n",
    "pinecone.init(api_key=pinecone_key, environment='gcp-starter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to be written to and read from\n",
    "index = pinecone.Index('document-embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors: 5\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for uploading to pinecone\n",
    "vectors = [{'id': str(i), 'values': [float(value) for value in embeddings[i]]} for i in range(len(embeddings))]\n",
    "print(f\"Number of vectors: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload embeddings to pinecone\n",
    "index.upsert(vectors=vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have uploaded the origional embedded documents to the index. Below, we will add a few more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# New documents\n",
    "new_documents = [\n",
    "    \"New document text here\",\n",
    "    \"Another new document text here\",\n",
    "    \"Uniqueness is very important, I will use it to find this vector!\"\n",
    "    # ... more documents\n",
    "]\n",
    "\n",
    "# Vectorize the new documents\n",
    "new_X = vectorizer.transform(new_documents)  # Note: use transform, not fit_transform, to keep the same vocabulary\n",
    "\n",
    "# Convert to dense array\n",
    "new_embeddings = new_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Existing Pinecone Index\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the new data for uploading to Pinecone\n",
    "start_id = len(embeddings)\n",
    "new_vectors = [{'id': str(start_id + i), 'values': [float(value) for value in new_embeddings[i]]} for i in range(len(new_embeddings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_response = index.upsert(vectors=new_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare and Query\n",
    "\n",
    "We have uploaded even more vectors to the index. Now, we need to retrieve some of them that are similar to a sentence I will write below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize new sentence\n",
    "new_sentence = \"I want to find the unique vector, it is important!\"\n",
    "new_vector = vectorizer.transform([new_sentence]).toarray()[0]  # Convert to dense array and get the first (and only) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the new vector to a list of standard Python float values\n",
    "new_vector_list = [float(value) for value in new_vector]\n",
    "\n",
    "# Query Pinecone for the most similar vector(s)\n",
    "query_response = index.query(\n",
    "    top_k=2,\n",
    "    vector=new_vector_list,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '3', 'score': 0.593876541, 'values': []},\n",
       " {'id': '7', 'score': 0.567467749, 'values': []}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_response['matches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the cosine similarity for the sentence I wrote and the one I wanted to find (the sentence with unique in it) is almost the highest at 0.7072.\n",
    "\n",
    "My query sentence: \"I want to find the unique vector, it is important!\"\n",
    "\n",
    "The sentences returned:\n",
    "1. The dog is lazy but the fox is quick\n",
    "2. Uniqueness is very important, I will use it to find this vector!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
