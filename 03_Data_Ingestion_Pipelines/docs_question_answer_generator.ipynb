{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"Role and Goal: \"VPC QuestGen\" specializes in generating high-quality Q&A pairs from AWS VPC documentation. The primary goal is to provide detailed and technically accurate explanations. When given a URL, the AI uses its web browsing capability to access and analyze the content of the provided link. The focus is on generating complete Q&A pairs that offer in-depth insights and comprehensive explanations, steering clear of partial or example-based answers.\n",
    "\n",
    "Task Simplification: The AI focuses on a single URL at a time provided later in this prompt. It uses the OpenAI API's web browsing feature to directly access the link, read the content, and generate Q&A pairs based on the information available on the page.\n",
    "\n",
    "Style and Format: The AI maintains a uniform format for the Q&A pairs, emphasizing clarity and thoroughness in the answers. It is tasked with providing high-quality Q&A pairs based on the web content accessed. Responses include the URL for transparency and traceability. The AI avoids displaying extraneous content, sticking strictly to generating Q&A pairs from the browsed content.\n",
    "\n",
    "Quality Assurance: The inclusion of the URL in responses enables source verification, ensuring the relevance and reliability of the information used. The AI is programmed to provide fully explanatory answers that cover all aspects of the query, based on the information available on the browsed page.\n",
    "\n",
    "Interaction Style: The AI adopts a formal, technical tone. It clearly states any limitations and ensures that responses are comprehensive and based solely on the content of the accessed URL.\n",
    "\n",
    "Personalization: The AI is optimized for efficiency, focusing on generating thorough and relevant Q&A pairs using information from the browsed URL. It does not engage in tasks beyond this scope.\n",
    "\n",
    "Error Handling: If the AI determines that the page lacks sufficient information to create high-quality Q&A pairs, it will return no response, adhering to the principle of quality over quantity in information delivery.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"VPC QuestGen's Role: Specialize in creating detailed, technically accurate Q&A pairs from AWS VPC documentation, using a URL provided later in this prompt. It employs the OpenAI API's web browsing feature to access and analyze linked content for generating comprehensive Q&A pairs.\n",
    "\n",
    "Task Focus: Handle one URL at a time, using the information from the link to produce Q&A pairs that are clear, thorough, and formatted uniformly. Responses include the URL for source verification.\n",
    "\n",
    "Quality and Style: The AI generates high-quality answers, maintaining a formal, technical tone. It avoids irrelevant content, focusing solely on the browsed URL's content. Responses cover all aspects of the query, ensuring relevance and reliability.\n",
    "\n",
    "Response Format: Each response should follow a strict format - (QUESTION: ..., ANSWER: ... ). Each Q&A pair must include the source URL at the end. Questions are to be concise and directly related to the content, while answers provide in-depth explanations.\n",
    "\n",
    "Limitations and Error Handling: The AI clearly states any limitations in the information available. If the page lacks enough data to create quality Q&A pairs, the AI will not provide a response, prioritizing quality over quantity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Import Libraries -----\n",
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- User Settings -----\n",
    "input_file_path = '../06_Data/Capstone_Data/Classified_VPC_Links.csv'\n",
    "output_file_path = '../06_Data/Capstone_Data/Documentation_QA_Pairs.csv'\n",
    "openai_api_key_env_var = \"OPENAI_KEY\"\n",
    "max_tokens = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed link 1/2\n",
      "Processed link 2/2\n",
      "Processed links with responses saved to: ../06_Data/Capstone_Data/Documentation_QA_Pairs.csv\n"
     ]
    }
   ],
   "source": [
    "# ----- Function Definitions -----\n",
    "def get_openai_response(url, custom_prompt_func, task):\n",
    "    prompt = custom_prompt_func(task, url)\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-1106-preview\",  # Use the chat model\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        # Adjust the response parsing for chat model output\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error in getting response: {e}\")\n",
    "        return None\n",
    "\n",
    "def scraping_prompt(task, url):\n",
    "    return f\"I am going to provide instructions on how to answer. Please follow them strictly: {task}, URL: {url}\"\n",
    "\n",
    "def process_vpc_links(file_path, output_path, task, custom_prompt_func=scraping_prompt, num_links=None):\n",
    "    links_df = pd.read_csv(file_path)\n",
    "    if num_links is not None:\n",
    "        links_df = links_df.head(num_links)\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    for index, row in links_df.iterrows():\n",
    "        url = row['LINK']\n",
    "        response = get_openai_response(url, custom_prompt_func, task)\n",
    "        responses.append(response)\n",
    "        print(f\"Processed link {index + 1}/{len(links_df)}\")\n",
    "\n",
    "    links_df['Response'] = responses\n",
    "    # links_df[['DESC', 'LINK', 'Question', 'Answer']] = links_df['Response'].str.split('\\n', expand=True)\n",
    "    # links_df.drop(columns=['Response'], inplace=True)\n",
    "\n",
    "    links_df.to_csv(output_path, index=False)\n",
    "    print(f\"Processed links with responses saved to: {output_path}\")\n",
    "\n",
    "# ----- Script Execution -----\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "openai_api_key_env_var = \"OPENAI_KEY\"\n",
    "openai.api_key = os.getenv(openai_api_key_env_var)\n",
    "\n",
    "input_file_path = '../06_Data/Capstone_Data/Classified_VPC_Links.csv'\n",
    "output_file_path = '../06_Data/Capstone_Data/Documentation_QA_Pairs.csv'\n",
    "\n",
    "# Process links and get responses, modify num_links to the desired number for testing\n",
    "process_vpc_links(input_file_path, output_file_path, task, num_links=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
