{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 19 21:18:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:05:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8    13W / 198W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 28%   38C    P8     7W / 180W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:09:00.0 Off |                  N/A |\n",
      "| 27%   34C    P8     7W / 180W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:0A:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8     7W / 198W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# package downlowed and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: gpg 1.16.0-unknown has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: gpg 1.16.0-unknown has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.36.0.dev0 requires tokenizers<0.15,>=0.14, but you have tokenizers 0.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: gpg 1.16.0-unknown has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: gpg 1.16.0-unknown has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: gpg 1.16.0-unknown has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==2.0.1 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (4.8.0)\n",
      "Requirement already satisfied: sympy in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.0.1) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from torch==2.0.1) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.37.1)\n",
      "Requirement already satisfied: cmake in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1) (3.27.7)\n",
      "Requirement already satisfied: lit in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1) (17.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /nfs/home/wzr5897/.local/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: gpg 1.16.0-unknown has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of gpg or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# You only need to run this once per machine\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib\n",
    "!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up accelerator\n",
    "\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to data/train_data.jsonl\n",
      "Evaluation data saved to data/validation_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "csv_file_path = 'data/vpc_raw_data.csv'\n",
    "train_jsonl_file_path = 'data/train_data.jsonl'\n",
    "eval_jsonl_file_path = 'data/validation_data.jsonl'\n",
    "train_ratio = 0.7  # Adjust this as needed\n",
    "\n",
    "# Read the CSV file and shuffle the rows\n",
    "with open(csv_file_path, mode='r', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    rows = list(csv_reader)\n",
    "    random.shuffle(rows)  # Shuffle the rows to randomize the data split\n",
    "\n",
    "# Compute the split index\n",
    "split_index = int(train_ratio * len(rows))\n",
    "\n",
    "# Split the rows into training and evaluation sets\n",
    "train_rows = rows[:split_index]\n",
    "eval_rows = rows[split_index:]\n",
    "\n",
    "# Function to write rows to a jsonl file\n",
    "def write_to_jsonl(file_path, rows):\n",
    "    with open(file_path, mode='w', encoding='utf-8') as file:\n",
    "        for row in rows:\n",
    "            json_object = {\n",
    "                'input': row['prompt'],\n",
    "                'output': row['response']\n",
    "            }\n",
    "            file.write(json.dumps(json_object) + '\\n')\n",
    "\n",
    "# Write the training and evaluation sets to their respective files\n",
    "write_to_jsonl(train_jsonl_file_path, train_rows)\n",
    "write_to_jsonl(eval_jsonl_file_path, eval_rows)\n",
    "\n",
    "print(f'Training data saved to {train_jsonl_file_path}')\n",
    "print(f'Evaluation data saved to {eval_jsonl_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc03ae558594eca817ab51bb947898c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069d5a77feec497997ecd3a20503fcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997d016d08a94caabc6e168ba13532dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0808be8d9a44cb9a312adf0e72a4c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b0c7b5900e457a9a6aa7c848052f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce801dd5b1b425e954b6b88eebf6890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initiate this chunk for reproducing what i did\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='data/train_data.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='data/validation_data.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formating prompt\n",
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8eb321652424b50ae4bd437b2d3e093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/wzr5897/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/nfs/home/wzr5897/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"NousResearch/Llama-2-7b-hf\" #weigts repo from hugging  face\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8964874543b462bba43b4962a4213dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/231 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2645daf580ca4bef83648f0fa910458e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenize_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 400 # This was an appropriate max length for my dataset \n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b654da50c399470a8d9c60c6b9e1bf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/231 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8747dbf19e14407946ea839d6b7cd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIjCAYAAAAJLyrXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLcUlEQVR4nO3deXxNd/7H8fdNZI8kQhYpQokl9qKa1qglBKkudCyjiqG6xNTaKl0spVottbTFdBFaSrUopvZ1qqpoLbXvayJ+VYkoSSTf3x995E6vBDmRDa/n43Ee437P957v53tzmLx7zvlemzHGCAAAAACQY06FXQAAAAAA3G4IUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIA7nrDhw+XzWYrkLGaNGmiJk2a2F+vW7dONptNX3/9dYGM3717d5UvX75Axsqt5ORk9erVS8HBwbLZbOrXr19hl5TnCvrnfjPLli1TnTp15O7uLpvNpgsXLmTbLzY2VjabTceOHSvQ+vKDlbmUL19e3bt3z/eaANxeCFIA7iiZvxxlbu7u7goJCVFUVJQmTZqkixcv5sk4Z86c0fDhw7V9+/Y8OV5eKsq15cRbb72l2NhYPf/88/r888/VtWvX6/YtX768HnnkkQKszprZs2drwoQJhV3GDf3222/q0KGDPDw89OGHH+rzzz+Xl5dXYZeVI3v27NHw4cPviGAH4PZTrLALAID8MHLkSFWoUEFpaWmKj4/XunXr1K9fP40fP16LFi1SrVq17H1fe+01vfLKK5aOf+bMGY0YMULly5dXnTp1cvy+FStWWBonN25U28cff6yMjIx8r+FWrFmzRg888ICGDRtW2KXcstmzZ+vXX38t0lfVtmzZoosXL+rNN99UZGTkDft27dpVnTp1kpubWwFVd2N79uzRiBEj1KRJE8tXWovaXADcfghSAO5IrVu3Vv369e2vhwwZojVr1uiRRx7Ro48+qr1798rDw0OSVKxYMRUrlr//HP7xxx/y9PSUq6trvo5zMy4uLoU6fk4kJCQoPDy8sMu4ayQkJEiS/Pz8btrX2dlZzs7O+VxRwbiT5gKgcHBrH4C7RrNmzfT666/r+PHj+uKLL+zt2T0jtXLlSjVq1Eh+fn7y9vZWlSpVNHToUEl/Pt/SoEEDSVKPHj3stxHGxsZK+vM5qBo1amjbtm1q3LixPD097e+99hmpTOnp6Ro6dKiCg4Pl5eWlRx99VCdPnnToc73nNP56zJvVlt0zUpcuXdLAgQNVtmxZubm5qUqVKnrvvfdkjHHoZ7PZ1KdPHy1cuFA1atSQm5ubqlevrmXLlmX/gV8jISFBPXv2VFBQkNzd3VW7dm3NmDHDvj/zuaGjR4/qP//5j732vLht64svvlC9evXk4eEhf39/derUKcvnm/lz27Nnj5o2bSpPT0/dc889Gjt2bJbjHT9+XI8++qi8vLwUGBio/v37a/ny5bLZbFq3bp39eP/5z390/Phx+1yu/ewzMjI0evRolSlTRu7u7mrevLkOHTrk0OfgwYNq3769goOD5e7urjJlyqhTp05KTEy86bznzZtnn3epUqX01FNP6fTp0w5z7tatmySpQYMGstlsN3wWKLvnijJvr/z+++91//33y93dXffee69mzpyZ7Xs3bNigZ599ViVLlpSPj4+efvpp/f777w59bTabhg8fnmX8v/4diI2N1d///ndJUtOmTe2fcebnfzPZzcUYo1GjRqlMmTLy9PRU06ZNtXv37izvTUtL04gRIxQWFiZ3d3eVLFlSjRo10sqVK3M0NoA7A1ekANxVunbtqqFDh2rFihV65plnsu2ze/duPfLII6pVq5ZGjhwpNzc3HTp0SBs3bpQkVatWTSNHjtQbb7yh3r17629/+5sk6cEHH7Qf47ffflPr1q3VqVMnPfXUUwoKCrphXaNHj5bNZtPgwYOVkJCgCRMmKDIyUtu3b7dfOcuJnNT2V8YYPfroo1q7dq169uypOnXqaPny5XrppZd0+vRpvf/++w79v//+e82fP18vvPCCihcvrkmTJql9+/Y6ceKESpYsed26Ll++rCZNmujQoUPq06ePKlSooHnz5ql79+66cOGC+vbtq2rVqunzzz9X//79VaZMGQ0cOFCSFBAQkOP5Z2f06NF6/fXX1aFDB/Xq1Uvnzp3T5MmT1bhxY/3yyy8OV2J+//13tWrVSu3atVOHDh309ddfa/DgwapZs6Zat24t6c/g2axZM8XFxalv374KDg7W7NmztXbtWodxX331VSUmJurUqVP2z9Hb29uhz9tvvy0nJycNGjRIiYmJGjt2rLp06aLNmzdLklJTUxUVFaWUlBT961//UnBwsE6fPq0lS5bowoUL8vX1ve68Y2Nj1aNHDzVo0EBjxozR2bNnNXHiRG3cuNE+71dffVVVqlTRv//9b/vtsBUrVrT8GR86dEhPPvmkevbsqW7duumzzz5T9+7dVa9ePVWvXt2hb58+feTn56fhw4dr//79mjJlio4fP24P0jnVuHFjvfjii5o0aZKGDh2qatWqSZL9f3PjjTfe0KhRo9SmTRu1adNGP//8s1q2bKnU1FSHfsOHD9eYMWPUq1cv3X///UpKStLWrVv1888/q0WLFrkeH8BtxgDAHWT69OlGktmyZct1+/j6+pq6devaXw8bNsz89Z/D999/30gy586du+4xtmzZYiSZ6dOnZ9n38MMPG0lm6tSp2e57+OGH7a/Xrl1rJJl77rnHJCUl2du/+uorI8lMnDjR3hYaGmq6det202PeqLZu3bqZ0NBQ++uFCxcaSWbUqFEO/Z588kljs9nMoUOH7G2SjKurq0Pbjh07jCQzefLkLGP91YQJE4wk88UXX9jbUlNTTUREhPH29naYe2hoqImOjr7h8XLa99ixY8bZ2dmMHj3aoX3Xrl2mWLFiDu2ZP7eZM2fa21JSUkxwcLBp3769vW3cuHFGklm4cKG97fLly6Zq1apGklm7dq29PTo62uHzzpT5c69WrZpJSUmxt0+cONFIMrt27TLGGPPLL78YSWbevHk3/zD+IjU11QQGBpoaNWqYy5cv29uXLFliJJk33njD3paTvzPX9j169Ki9LTQ01EgyGzZssLclJCQYNzc3M3DgwCzvrVevnklNTbW3jx071kgy3377rb1Nkhk2bFiW8a/9OzBv3rwsn3lOXTuXhIQE4+rqaqKjo01GRoa939ChQ40kh3Fr166d43MUwJ2LW/sA3HW8vb1vuHpf5hWKb7/9NtcLM7i5ualHjx457v/000+rePHi9tdPPvmkSpcure+++y5X4+fUd999J2dnZ7344osO7QMHDpQxRkuXLnVoj4yMdLhiUatWLfn4+OjIkSM3HSc4OFidO3e2t7m4uOjFF19UcnKy1q9fnwezyWr+/PnKyMhQhw4d9H//93/2LTg4WGFhYVmuInl7e+upp56yv3Z1ddX999/vML9ly5bpnnvu0aOPPmpvc3d3v+4Vzhvp0aOHw3NzmVcQM8fLvOK0fPly/fHHHzk+7tatW5WQkKAXXnhB7u7u9vbo6GhVrVpV//nPfyzXeiPh4eH22qU/ryJWqVIl2/Oid+/eDs/qPf/88ypWrFi+n+s3s2rVKqWmpupf//qXw5Wx7BYK8fPz0+7du3Xw4MECrBBAUUOQAnDXSU5Odggt1+rYsaMeeugh9erVS0FBQerUqZO++uorS6HqnnvusbSwRFhYmMNrm82mSpUq5fuyzsePH1dISEiWzyPz9qjjx487tJcrVy7LMUqUKJHlGZfsxgkLC5OTk+P/7VxvnLxy8OBBGWMUFhamgIAAh23v3r32hRYylSlTJsvtZdfO7/jx46pYsWKWfpUqVbJc37WfZ4kSJSTJPl6FChU0YMAAffLJJypVqpSioqL04Ycf3vT5qMzPs0qVKln2Va1aNc8/byvnxbXnure3t0qXLl3oS5hnfibX1hcQEGD/uWQaOXKkLly4oMqVK6tmzZp66aWXtHPnzgKrFUDRQJACcFc5deqUEhMTb/hLr4eHhzZs2KBVq1apa9eu2rlzpzp27KgWLVooPT09R+NYea4pp673/EhOa8oL11vlzFyzMEVRkZGRIZvNpmXLlmnlypVZtmnTpjn0L+j55WS8cePGaefOnRo6dKguX76sF198UdWrV9epU6fypabcKKjPrSDP9Rtp3LixDh8+rM8++0w1atTQJ598ovvuu0+ffPJJYZcGoAARpADcVT7//HNJUlRU1A37OTk5qXnz5ho/frz27Nmj0aNHa82aNfZbwaw8FJ8T194iZIzRoUOHHFZ5K1GihC5cuJDlvddeXbBSW2hoqM6cOZPlVsd9+/bZ9+eF0NBQHTx4MMtVvbwe51oVK1aUMUYVKlRQZGRklu2BBx6wfMzQ0FAdPnw4S0i4drU9Ke/Ok5o1a+q1117Thg0b9N///lenT5/W1KlTb1ijJO3fvz/Lvv379+fb550T157rycnJiouLu+m5npqaqri4OIe2vPx7mPmZXFvfuXPnsr2y5u/vrx49eujLL7/UyZMnVatWrWxXGgRw5yJIAbhrrFmzRm+++aYqVKigLl26XLff+fPns7RlfrFtSkqKJMnLy0uSsg02uTFz5kyHMPP1118rLi7OvlKc9Gco+PHHHx1WEFuyZEmWZbyt1NamTRulp6frgw8+cGh///33ZbPZHMa/FW3atFF8fLzmzp1rb7t69aomT54sb29vPfzww3kyzrXatWsnZ2dnjRgxIkvwMcbot99+s3zMqKgonT59WosWLbK3XblyRR9//HGWvl5eXjlapvx6kpKSdPXqVYe2mjVrysnJyX4uZqd+/foKDAzU1KlTHfotXbpUe/fuVXR0dK5rulX//ve/lZaWZn89ZcoUXb16Ncu5vmHDhizvu/aKVF7+PYyMjJSLi4smT57scK5MmDAhS99rzxtvb29VqlTphj8TAHcelj8HcEdaunSp9u3bp6tXr+rs2bNas2aNVq5cqdDQUC1atMjhAfxrjRw5Uhs2bFB0dLRCQ0OVkJCgjz76SGXKlFGjRo0k/fmLnp+fn6ZOnarixYvLy8tLDRs2VIUKFXJVr7+/vxo1aqQePXro7NmzmjBhgipVquSwgEGvXr309ddfq1WrVurQoYMOHz6sL774Isty1VZqa9u2rZo2bapXX31Vx44dU+3atbVixQp9++236tevX66Wws5O7969NW3aNHXv3l3btm1T+fLl9fXXX2vjxo2aMGHCDZ9Zu5lDhw5p1KhRWdrr1q2r6OhojRo1SkOGDNGxY8f0+OOPq3jx4jp69KgWLFig3r17a9CgQZbGe/bZZ/XBBx+oc+fO6tu3r0qXLq1Zs2bZz6m/XiWpV6+e5s6dqwEDBqhBgwby9vZW27ZtczzWmjVr1KdPH/39739X5cqVdfXqVX3++edydnZW+/btr/s+FxcXvfPOO+rRo4cefvhhde7c2b78efny5dW/f39Lc85Lqampat68uTp06KD9+/fro48+UqNGjRwW7+jVq5eee+45tW/fXi1atNCOHTu0fPlylSpVyuFYderUkbOzs9555x0lJibKzc1NzZo1U2BgoOW6AgICNGjQII0ZM0aPPPKI2rRpo19++UVLly7NMm54eLiaNGmievXqyd/fX1u3btXXX3+tPn365O5DAXB7KpzFAgEgf2QuaZy5ubq6muDgYNOiRQszceJEh2W2M127/Pnq1avNY489ZkJCQoyrq6sJCQkxnTt3NgcOHHB437fffmvCw8NNsWLFHJYbf/jhh0316tWzre96y59/+eWXZsiQISYwMNB4eHiY6Ohoc/z48SzvHzdunLnnnnuMm5ubeeihh8zWrVuzHPNGtV27/Lkxxly8eNH079/fhISEGBcXFxMWFmbeffddhyWgjflzSeqYmJgsNV1vWfZrnT171vTo0cOUKlXKuLq6mpo1a2a7RLvV5c//+vP+69azZ097v2+++cY0atTIeHl5GS8vL1O1alUTExNj9u/fb+9zvZ9bdp/ZkSNHTHR0tPHw8DABAQFm4MCB5ptvvjGSzI8//mjvl5ycbP7xj38YPz8/I8l+nMyf+7XLmh89etTh53XkyBHzz3/+01SsWNG4u7sbf39/07RpU7Nq1aocfT5z5841devWNW5ubsbf39906dLFnDp1yqFPXix/nt3P69rzMvO969evN7179zYlSpQw3t7epkuXLua3335zeG96eroZPHiwKVWqlPH09DRRUVHm0KFD2Z5rH3/8sbn33nuNs7OzpaXQs5tLenq6GTFihCldurTx8PAwTZo0Mb/++muWcUeNGmXuv/9+4+fnZzw8PEzVqlXN6NGjHZZ1B3DnsxlTRJ8QBgDgNjJhwgT1799fp06d0j333FPY5RQ5mV8QvGXLFtWvX7+wywGAW8YzUgAAWHT58mWH11euXNG0adMUFhZGiAKAuwTPSAEAYFG7du1Urlw51alTR4mJifriiy+0b98+zZo1q7BLu+slJycrOTn5hn0CAgKuu2Q7AOQUQQoAAIuioqL0ySefaNasWUpPT1d4eLjmzJmjjh07FnZpd7333ntPI0aMuGGfo0ePOiy3DgC5wTNSAADgjnHkyBEdOXLkhn0aNWp0w5U7ASAnCFIAAAAAYBGLTQAAAACARTwjJSkjI0NnzpxR8eLFHb5IEQAAAMDdxRijixcvKiQkRE5O17/uRJCSdObMGZUtW7awywAAAABQRJw8eVJlypS57n6ClKTixYtL+vPD8vHxKeRqAAAAABSWpKQklS1b1p4RrocgJdlv5/Px8SFIAQAAALjpIz8sNgEAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYVKywCwAAoKho27awK/ifxYsLuwIAwI1wRQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhVqkJoyZYpq1aolHx8f+fj4KCIiQkuXLrXvv3LlimJiYlSyZEl5e3urffv2Onv2rMMxTpw4oejoaHl6eiowMFAvvfSSrl69WtBTAQAAAHAXKdQgVaZMGb399tvatm2btm7dqmbNmumxxx7T7t27JUn9+/fX4sWLNW/ePK1fv15nzpxRu3bt7O9PT09XdHS0UlNT9cMPP2jGjBmKjY3VG2+8UVhTAgAAAHAXsBljTGEX8Vf+/v5699139eSTTyogIECzZ8/Wk08+KUnat2+fqlWrpk2bNumBBx7Q0qVL9cgjj+jMmTMKCgqSJE2dOlWDBw/WuXPn5OrqmqMxk5KS5Ovrq8TERPn4+OTb3AAARVvbtoVdwf8sXlzYFQDA3Smn2aDIPCOVnp6uOXPm6NKlS4qIiNC2bduUlpamyMhIe5+qVauqXLly2rRpkyRp06ZNqlmzpj1ESVJUVJSSkpLsV7Wyk5KSoqSkJIcNAAAAAHKq0IPUrl275O3tLTc3Nz333HNasGCBwsPDFR8fL1dXV/n5+Tn0DwoKUnx8vCQpPj7eIURl7s/cdz1jxoyRr6+vfStbtmzeTgoAAADAHa3Qg1SVKlW0fft2bd68Wc8//7y6deumPXv25OuYQ4YMUWJion07efJkvo4HAAAA4M5SrLALcHV1VaVKlSRJ9erV05YtWzRx4kR17NhRqampunDhgsNVqbNnzyo4OFiSFBwcrJ9++snheJmr+mX2yY6bm5vc3NzyeCYAAAAA7haFfkXqWhkZGUpJSVG9evXk4uKi1atX2/ft379fJ06cUEREhCQpIiJCu3btUkJCgr3PypUr5ePjo/Dw8AKvHQAAAMDdoVCvSA0ZMkStW7dWuXLldPHiRc2ePVvr1q3T8uXL5evrq549e2rAgAHy9/eXj4+P/vWvfykiIkIPPPCAJKlly5YKDw9X165dNXbsWMXHx+u1115TTEwMV5wAAAAA5JtCDVIJCQl6+umnFRcXJ19fX9WqVUvLly9XixYtJEnvv/++nJyc1L59e6WkpCgqKkofffSR/f3Ozs5asmSJnn/+eUVERMjLy0vdunXTyJEjC2tKAAAAAO4CRe57pAoD3yMFAJD4HikAwG34PVIAAAAAcLsgSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYFGhBqkxY8aoQYMGKl68uAIDA/X4449r//79Dn2aNGkim83msD333HMOfU6cOKHo6Gh5enoqMDBQL730kq5evVqQUwEAAABwFylWmIOvX79eMTExatCgga5evaqhQ4eqZcuW2rNnj7y8vOz9nnnmGY0cOdL+2tPT0/7n9PR0RUdHKzg4WD/88IPi4uL09NNPy8XFRW+99VaBzgcAAADA3aFQg9SyZcscXsfGxiowMFDbtm1T48aN7e2enp4KDg7O9hgrVqzQnj17tGrVKgUFBalOnTp68803NXjwYA0fPlyurq5Z3pOSkqKUlBT766SkpDyaEQAAAIC7QZF6RioxMVGS5O/v79A+a9YslSpVSjVq1NCQIUP0xx9/2Pdt2rRJNWvWVFBQkL0tKipKSUlJ2r17d7bjjBkzRr6+vvatbNmy+TAbAAAAAHeqQr0i9VcZGRnq16+fHnroIdWoUcPe/o9//EOhoaEKCQnRzp07NXjwYO3fv1/z58+XJMXHxzuEKEn21/Hx8dmONWTIEA0YMMD+OikpiTAFAAAAIMeKTJCKiYnRr7/+qu+//96hvXfv3vY/16xZU6VLl1bz5s11+PBhVaxYMVdjubm5yc3N7ZbqBQAAAHD3KhK39vXp00dLlizR2rVrVaZMmRv2bdiwoSTp0KFDkqTg4GCdPXvWoU/m6+s9VwUAAAAAt6JQg5QxRn369NGCBQu0Zs0aVahQ4abv2b59uySpdOnSkqSIiAjt2rVLCQkJ9j4rV66Uj4+PwsPD86VuAAAAAHe3Qr21LyYmRrNnz9a3336r4sWL259p8vX1lYeHhw4fPqzZs2erTZs2KlmypHbu3Kn+/furcePGqlWrliSpZcuWCg8PV9euXTV27FjFx8frtddeU0xMDLfvAQAAAMgXhXpFasqUKUpMTFSTJk1UunRp+zZ37lxJkqurq1atWqWWLVuqatWqGjhwoNq3b6/Fixfbj+Hs7KwlS5bI2dlZEREReuqpp/T00087fO8UAAAAAOSlQr0iZYy54f6yZctq/fr1Nz1OaGiovvvuu7wqCwAAAABuqEgsNgEAAAAAtxOCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCoUIPUmDFj1KBBAxUvXlyBgYF6/PHHtX//foc+V65cUUxMjEqWLClvb2+1b99eZ8+edehz4sQJRUdHy9PTU4GBgXrppZd09erVgpwKAAAAgLtIoQap9evXKyYmRj/++KNWrlyptLQ0tWzZUpcuXbL36d+/vxYvXqx58+Zp/fr1OnPmjNq1a2ffn56erujoaKWmpuqHH37QjBkzFBsbqzfeeKMwpgQAAADgLmAzxpjCLiLTuXPnFBgYqPXr16tx48ZKTExUQECAZs+erSeffFKStG/fPlWrVk2bNm3SAw88oKVLl+qRRx7RmTNnFBQUJEmaOnWqBg8erHPnzsnV1fWm4yYlJcnX11eJiYny8fHJ1zkCAIqutm0Lu4L/Wby4sCsAgLtTTrNBkXpGKjExUZLk7+8vSdq2bZvS0tIUGRlp71O1alWVK1dOmzZtkiRt2rRJNWvWtIcoSYqKilJSUpJ2796d7TgpKSlKSkpy2AAAAAAgp4pMkMrIyFC/fv300EMPqUaNGpKk+Ph4ubq6ys/Pz6FvUFCQ4uPj7X3+GqIy92fuy86YMWPk6+tr38qWLZvHswEAAABwJysyQSomJka//vqr5syZk+9jDRkyRImJifbt5MmT+T4mAAAAgDtHroLUkSNH8rSIPn36aMmSJVq7dq3KlCljbw8ODlZqaqouXLjg0P/s2bMKDg6297l2Fb/M15l9ruXm5iYfHx+HDQAAAAByKldBqlKlSmratKm++OILXblyJdeDG2PUp08fLViwQGvWrFGFChUc9terV08uLi5avXq1vW3//v06ceKEIiIiJEkRERHatWuXEhIS7H1WrlwpHx8fhYeH57o2AAAAALieXAWpn3/+WbVq1dKAAQMUHBysZ599Vj/99JPl48TExOiLL77Q7NmzVbx4ccXHxys+Pl6XL1+WJPn6+qpnz54aMGCA1q5dq23btqlHjx6KiIjQAw88IElq2bKlwsPD1bVrV+3YsUPLly/Xa6+9ppiYGLm5ueVmegAAAABwQ7e0/PnVq1e1aNEixcbGatmyZapcubL++c9/qmvXrgoICLj54DZbtu3Tp09X9+7dJf35hbwDBw7Ul19+qZSUFEVFRemjjz5yuG3v+PHjev7557Vu3Tp5eXmpW7duevvtt1WsWLEczYPlzwEAEsufAwByng3y5HukUlJS9NFHH2nIkCFKTU2Vq6urOnTooHfeeUelS5e+1cPnO4IUAEAiSAEACuh7pLZu3aoXXnhBpUuX1vjx4zVo0CAdPnxYK1eu1JkzZ/TYY4/dyuEBAAAAoEjK2b1v1xg/frymT5+u/fv3q02bNpo5c6batGkjJ6c/c1mFChUUGxur8uXL52WtAAAAAFAk5CpITZkyRf/85z/VvXv36966FxgYqE8//fSWigMAAACAoihXQergwYM37ePq6qpu3brl5vAAAAAAUKTl6hmp6dOna968eVna582bpxkzZtxyUQAAAABQlOUqSI0ZM0alSpXK0h4YGKi33nrrlosCAAAAgKIsV0HqxIkTqlChQpb20NBQnThx4paLAgAAAICiLFdBKjAwUDt37szSvmPHDpUsWfKWiwIAAACAoixXQapz58568cUXtXbtWqWnpys9PV1r1qxR37591alTp7yuEQAAAACKlFyt2vfmm2/q2LFjat68uYoV+/MQGRkZevrpp3lGCgAAAMAdL1dBytXVVXPnztWbb76pHTt2yMPDQzVr1lRoaGhe1wcAAAAARU6uglSmypUrq3LlynlVCwAAAADcFnIVpNLT0xUbG6vVq1crISFBGRkZDvvXrFmTJ8UBAAAAQFGUqyDVt29fxcbGKjo6WjVq1JDNZsvrugAAAACgyMpVkJozZ46++uortWnTJq/rAQAAAIAiL1fLn7u6uqpSpUp5XQsAAAAA3BZyFaQGDhyoiRMnyhiT1/UAAAAAQJGXq1v7vv/+e61du1ZLly5V9erV5eLi4rB//vz5eVIcAAAAABRFuQpSfn5+euKJJ/K6FgAAAAC4LeQqSE2fPj2v6wAAAACA20aunpGSpKtXr2rVqlWaNm2aLl68KEk6c+aMkpOT86w4AAAAACiKcnVF6vjx42rVqpVOnDihlJQUtWjRQsWLF9c777yjlJQUTZ06Na/rBAAAAIAiI1dXpPr27av69evr999/l4eHh739iSee0OrVq/OsOAAAAAAoinJ1Req///2vfvjhB7m6ujq0ly9fXqdPn86TwgAAAACgqMrVFamMjAylp6dnaT916pSKFy9+y0UBAAAAQFGWqyDVsmVLTZgwwf7aZrMpOTlZw4YNU5s2bfKqNgAAAAAoknJ1a9+4ceMUFRWl8PBwXblyRf/4xz908OBBlSpVSl9++WVe1wgAAAAARUquglSZMmW0Y8cOzZkzRzt37lRycrJ69uypLl26OCw+AQAAAAB3olwFKUkqVqyYnnrqqbysBQAAAABuC7kKUjNnzrzh/qeffjpXxQAAAADA7SBXQapv374Or9PS0vTHH3/I1dVVnp6eBCkAAAAAd7Rcrdr3+++/O2zJycnav3+/GjVqxGITAAAAAO54uQpS2QkLC9Pbb7+d5WoVAAAAANxp8ixISX8uQHHmzJm8PCQAAAAAFDm5ekZq0aJFDq+NMYqLi9MHH3yghx56KE8KAwAAAICiKldB6vHHH3d4bbPZFBAQoGbNmmncuHF5URcAAAAAFFm5ClIZGRl5XQcAAAAA3Dby9BkpAAAAALgb5OqK1IABA3Lcd/z48bkZAgAAAACKrFwFqV9++UW//PKL0tLSVKVKFUnSgQMH5OzsrPvuu8/ez2az5U2VAAAAAFCE5CpItW3bVsWLF9eMGTNUokQJSX9+SW+PHj30t7/9TQMHDszTIgEAAACgKLEZY4zVN91zzz1asWKFqlev7tD+66+/qmXLlrfdd0klJSXJ19dXiYmJ8vHxKexyAACFpG3bwq7gfxYvLuwKAODulNNskKvFJpKSknTu3Lks7efOndPFixdzc0gAAAAAuG3kKkg98cQT6tGjh+bPn69Tp07p1KlT+uabb9SzZ0+1a9cur2sEAAAAgCIlV89ITZ06VYMGDdI//vEPpaWl/XmgYsXUs2dPvfvuu3laIAAAAAAUNbl6RirTpUuXdPjwYUlSxYoV5eXllWeFFSSekQIASDwjBQDI52ekMsXFxSkuLk5hYWHy8vLSLWQyAAAAALht5CpI/fbbb2revLkqV66sNm3aKC4uTpLUs2dPlj4HAAAAcMfLVZDq37+/XFxcdOLECXl6etrbO3bsqGXLluVZcQAAAABQFOVqsYkVK1Zo+fLlKlOmjEN7WFiYjh8/nieFAQAAAEBRlasrUpcuXXK4EpXp/PnzcnNzu+WiAAAAAKAoy1WQ+tvf/qaZM2faX9tsNmVkZGjs2LFq2rRpnhUHAAAAAEVRrm7tGzt2rJo3b66tW7cqNTVVL7/8snbv3q3z589r48aNeV0jAAAAABQpuboiVaNGDR04cECNGjXSY489pkuXLqldu3b65ZdfVLFixbyuEQAAAACKFMtXpNLS0tSqVStNnTpVr776an7UBAAAAABFmuUrUi4uLtq5c2eeDL5hwwa1bdtWISEhstlsWrhwocP+7t27y2azOWytWrVy6HP+/Hl16dJFPj4+8vPzU8+ePZWcnJwn9QEAAABAdnJ1a99TTz2lTz/99JYHv3TpkmrXrq0PP/zwun1atWqluLg4+/bll1867O/SpYt2796tlStXasmSJdqwYYN69+59y7UBAAAAwPXkarGJq1ev6rPPPtOqVatUr149eXl5OewfP358jo7TunVrtW7d+oZ93NzcFBwcnO2+vXv3atmyZdqyZYvq168vSZo8ebLatGmj9957TyEhITmqAwAAAACssBSkjhw5ovLly+vXX3/VfffdJ0k6cOCAQx+bzZZ31Ulat26dAgMDVaJECTVr1kyjRo1SyZIlJUmbNm2Sn5+fPURJUmRkpJycnLR582Y98cQT2R4zJSVFKSkp9tdJSUl5WjMAAACAO5ulIBUWFqa4uDitXbtWktSxY0dNmjRJQUFB+VJcq1at1K5dO1WoUEGHDx/W0KFD1bp1a23atEnOzs6Kj49XYGCgw3uKFSsmf39/xcfHX/e4Y8aM0YgRI/KlZgAAAAB3PktByhjj8Hrp0qW6dOlSnhb0V506dbL/uWbNmqpVq5YqVqyodevWqXnz5rk+7pAhQzRgwAD766SkJJUtW/aWagUAAABw98jVYhOZrg1W+e3ee+9VqVKldOjQIUlScHCwEhISHPpcvXpV58+fv+5zVdKfz135+Pg4bAAAAACQU5aCVOYS5Ne2FZRTp07pt99+U+nSpSVJERERunDhgrZt22bvs2bNGmVkZKhhw4YFVhcAAACAu4vlW/u6d+8uNzc3SdKVK1f03HPPZVm1b/78+Tk6XnJysv3qkiQdPXpU27dvl7+/v/z9/TVixAi1b99ewcHBOnz4sF5++WVVqlRJUVFRkqRq1aqpVatWeuaZZzR16lSlpaWpT58+6tSpEyv2AQAAAMg3loJUt27dHF4/9dRTtzT41q1b1bRpU/vrzOeWunXrpilTpmjnzp2aMWOGLly4oJCQELVs2VJvvvmmPchJ0qxZs9SnTx81b95cTk5Oat++vSZNmnRLdQEAAADAjdhMQT/oVAQlJSXJ19dXiYmJPC8FAHextm0Lu4L/Wby4sCsAgLtTTrPBLS02AQAAAAB3I4IUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWFWqQ2rBhg9q2bauQkBDZbDYtXLjQYb8xRm+88YZKly4tDw8PRUZG6uDBgw59zp8/ry5dusjHx0d+fn7q2bOnkpOTC3AWAAAAAO42hRqkLl26pNq1a+vDDz/Mdv/YsWM1adIkTZ06VZs3b5aXl5eioqJ05coVe58uXbpo9+7dWrlypZYsWaINGzaod+/eBTUFAAAAAHchmzHGFHYRkmSz2bRgwQI9/vjjkv68GhUSEqKBAwdq0KBBkqTExEQFBQUpNjZWnTp10t69exUeHq4tW7aofv36kqRly5apTZs2OnXqlEJCQnI0dlJSknx9fZWYmCgfH598mR8AoOhr27awK/ifxYsLuwIAuDvlNBsU2Wekjh49qvj4eEVGRtrbfH191bBhQ23atEmStGnTJvn5+dlDlCRFRkbKyclJmzdvvu6xU1JSlJSU5LABAAAAQE4V2SAVHx8vSQoKCnJoDwoKsu+Lj49XYGCgw/5ixYrJ39/f3ic7Y8aMka+vr30rW7ZsHlcPAAAA4E5WZINUfhoyZIgSExPt28mTJwu7JAAAAAC3kSIbpIKDgyVJZ8+edWg/e/asfV9wcLASEhIc9l+9elXnz5+398mOm5ubfHx8HDYAAAAAyKkiG6QqVKig4OBgrV692t6WlJSkzZs3KyIiQpIUERGhCxcuaNu2bfY+a9asUUZGhho2bFjgNQMAAAC4OxQrzMGTk5N16NAh++ujR49q+/bt8vf3V7ly5dSvXz+NGjVKYWFhqlChgl5//XWFhITYV/arVq2aWrVqpWeeeUZTp05VWlqa+vTpo06dOuV4xT4AAAAAsKpQg9TWrVvVtGlT++sBAwZIkrp166bY2Fi9/PLLunTpknr37q0LFy6oUaNGWrZsmdzd3e3vmTVrlvr06aPmzZvLyclJ7du316RJkwp8LgAAAADuHkXme6QKE98jBQCQ+B4pAMAd8D1SAAAAAFBUEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARUU6SA0fPlw2m81hq1q1qn3/lStXFBMTo5IlS8rb21vt27fX2bNnC7FiAAAAAHeDIh2kJKl69eqKi4uzb99//719X//+/bV48WLNmzdP69ev15kzZ9SuXbtCrBYAAADA3aBYYRdwM8WKFVNwcHCW9sTERH366aeaPXu2mjVrJkmaPn26qlWrph9//FEPPPBAQZcKAAAA4C5R5K9IHTx4UCEhIbr33nvVpUsXnThxQpK0bds2paWlKTIy0t63atWqKleunDZt2nTDY6akpCgpKclhAwAAAICcKtJBqmHDhoqNjdWyZcs0ZcoUHT16VH/729908eJFxcfHy9XVVX5+fg7vCQoKUnx8/A2PO2bMGPn6+tq3smXL5uMsAAAAANxpivStfa1bt7b/uVatWmrYsKFCQ0P11VdfycPDI9fHHTJkiAYMGGB/nZSURJgCAAAAkGNF+orUtfz8/FS5cmUdOnRIwcHBSk1N1YULFxz6nD17Nttnqv7Kzc1NPj4+DhsAAAAA5NRtFaSSk5N1+PBhlS5dWvXq1ZOLi4tWr15t379//36dOHFCERERhVglAAAAgDtdkb61b9CgQWrbtq1CQ0N15swZDRs2TM7OzurcubN8fX3Vs2dPDRgwQP7+/vLx8dG//vUvRUREsGIfAAAAgHxVpIPUqVOn1LlzZ/32228KCAhQo0aN9OOPPyogIECS9P7778vJyUnt27dXSkqKoqKi9NFHHxVy1QAAAADudDZjjCnsIgpbUlKSfH19lZiYyPNSAHAXa9u2sCv4n8WLC7sCALg75TQb3FbPSAEAAABAUUCQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAojsmSH344YcqX7683N3d1bBhQ/3000+FXRIAAACAO9QdEaTmzp2rAQMGaNiwYfr5559Vu3ZtRUVFKSEhobBLAwAAAHAHuiOC1Pjx4/XMM8+oR48eCg8P19SpU+Xp6anPPvussEsDAAAAcAcqVtgF3KrU1FRt27ZNQ4YMsbc5OTkpMjJSmzZtyvY9KSkpSklJsb9OTEyUJCUlJeVvsQCAIi0trbAr+B/+LwkACkdmJjDG3LDfbR+k/u///k/p6ekKCgpyaA8KCtK+ffuyfc+YMWM0YsSILO1ly5bNlxoBALDK17ewKwCAu9vFixfle4N/jG/7IJUbQ4YM0YABA+yvMzIydP78eZUsWVI2m60QK8P1JCUlqWzZsjp58qR8fHwKuxzcBjhnYBXnDKzinIFVnDO3B2OMLl68qJCQkBv2u+2DVKlSpeTs7KyzZ886tJ89e1bBwcHZvsfNzU1ubm4ObX5+fvlVIvKQj48P//DAEs4ZWMU5A6s4Z2AV50zRd6MrUZlu+8UmXF1dVa9ePa1evdrelpGRodWrVysiIqIQKwMAAABwp7rtr0hJ0oABA9StWzfVr19f999/vyZMmKBLly6pR48ehV0aAAAAgDvQHRGkOnbsqHPnzumNN95QfHy86tSpo2XLlmVZgAK3Lzc3Nw0bNizLLZnA9XDOwCrOGVjFOQOrOGfuLDZzs3X9AAAAAAAObvtnpAAAAACgoBGkAAAAAMAighQAAAAAWESQAgAAAACLCFLId1OmTFGtWrXsXz4XERGhpUuX2vcfPnxYTzzxhAICAuTj46MOHTpk+YLln3/+WS1atJCfn59Kliyp3r17Kzk5+aZj7927V48++qh8fX3l5eWlBg0a6MSJE3k+R+SdwjpfkpOT1adPH5UpU0YeHh4KDw/X1KlT82WOyF9vv/22bDab+vXrZ2+7cuWKYmJiVLJkSXl7e6t9+/ZZzpsTJ04oOjpanp6eCgwM1EsvvaSrV6/ecKzz58+rS5cu8vHxkZ+fn3r27Jmjf5tQtBTUOXPs2DH17NlTFSpUkIeHhypWrKhhw4YpNTU1v6aGfFKQ/85kSklJUZ06dWSz2bR9+/Y8nA1yiyCFfFemTBm9/fbb2rZtm7Zu3apmzZrpscce0+7du3Xp0iW1bNlSNptNa9as0caNG5Wamqq2bdsqIyNDknTmzBlFRkaqUqVK2rx5s5YtW6bdu3ere/fuNxz38OHDatSokapWrap169Zp586dev311+Xu7l4As0ZuFdb5MmDAAC1btkxffPGF9u7dq379+qlPnz5atGhRAcwaeWXLli2aNm2aatWq5dDev39/LV68WPPmzdP69et15swZtWvXzr4/PT1d0dHRSk1N1Q8//KAZM2YoNjZWb7zxxg3H69Kli3bv3q2VK1dqyZIl2rBhg3r37p0vc0P+KMhzZt++fcrIyNC0adO0e/duvf/++5o6daqGDh2ab/ND3ivof2cyvfzyywoJCcnTueAWGaAQlChRwnzyySdm+fLlxsnJySQmJtr3XbhwwdhsNrNy5UpjjDHTpk0zgYGBJj093d5n586dRpI5ePDgdcfo2LGjeeqpp/JvEigwBXG+VK9e3YwcOdKh7b777jOvvvpqHs8G+eXixYsmLCzMrFy50jz88MOmb9++xpg/zxEXFxczb948e9+9e/caSWbTpk3GGGO+++474+TkZOLj4+19pkyZYnx8fExKSkq24+3Zs8dIMlu2bLG3LV261NhsNnP69Ol8mCHyWkGfM9kZO3asqVChQt5MCPmusM6Z7777zlStWtXs3r3bSDK//PJLns8N1nFFCgUqPT1dc+bM0aVLlxQREaGUlBTZbDaHL6Zzd3eXk5OTvv/+e0l/Xsp2dXWVk9P/TlcPDw9Jsve5VkZGhv7zn/+ocuXKioqKUmBgoBo2bKiFCxfm3+SQ5wrqfJGkBx98UIsWLdLp06dljNHatWt14MABtWzZMp9mh7wWExOj6OhoRUZGOrRv27ZNaWlpDu1Vq1ZVuXLltGnTJknSpk2bVLNmTYcvco+KilJSUpJ2796d7XibNm2Sn5+f6tevb2+LjIyUk5OTNm/enJdTQz4p6HMmO4mJifL397/FmaCgFMY5c/bsWT3zzDP6/PPP5enpmcczwq0gSKFA7Nq1S97e3nJzc9Nzzz2nBQsWKDw8XA888IC8vLw0ePBg/fHHH7p06ZIGDRqk9PR0xcXFSZKaNWum+Ph4vfvuu0pNTdXvv/+uV155RZLsfa6VkJCg5ORkvf3222rVqpVWrFihJ554Qu3atdP69esLbN7InYI+XyRp8uTJCg8PV5kyZeTq6qpWrVrpww8/VOPGjQtkzrg1c+bM0c8//6wxY8Zk2RcfHy9XV1f5+fk5tAcFBSk+Pt7e56+/3GTuz9yXnfj4eAUGBjq0FStWTP7+/td9D4qOwjhnrnXo0CFNnjxZzz77bC5mgIJWGOeMMUbdu3fXc8895/AfbVA0EKRQIKpUqaLt27dr8+bNev7559WtWzft2bNHAQEBmjdvnhYvXixvb2/5+vrqwoULuu++++xXFKpXr64ZM2Zo3Lhx8vT0VHBwsCpUqKCgoCCHqw5/lfm8zGOPPab+/furTp06euWVV/TII4+wgMBtoKDPF+nPIPXjjz9q0aJF2rZtm8aNG6eYmBitWrWqoKaNXDp58qT69u2rWbNm8QwkcqQonDOnT59Wq1at9Pe//13PPPNModSAnCusc2by5Mm6ePGihgwZUmBjwoLCvrcQd6fmzZub3r17O7SdO3fO/P7778YYY4KCgszYsWOzvC8+Pt5cvHjRJCcnGycnJ/PVV19le/yUlBRTrFgx8+abbzq0v/zyy+bBBx/Mm0mgwOT3+fLHH38YFxcXs2TJEof2nj17mqioqLyZBPLNggULjCTj7Oxs3yQZm81mnJ2dzapVq4wk+/mSqVy5cmb8+PHGGGNef/11U7t2bYf9R44cMZLMzz//nO24n376qfHz83NoS0tLM87Ozmb+/Pl5Nj/kvcI6ZzKdPn3ahIWFma5duzo8z4miq7DOmccee8w4OTllGdfZ2dk8/fTT+TFVWMAVKRSKjIwMpaSkOLSVKlVKfn5+WrNmjRISEvToo49meV9QUJC8vb01d+5cubu7q0WLFtke39XVVQ0aNND+/fsd2g8cOKDQ0NC8mwgKRH6fL2lpaUpLS8tyxcrZ2dl+dRNFV/PmzbVr1y5t377dvtWvX19dunSx/9nFxUWrV6+2v2f//v06ceKEIiIiJEkRERHatWuXEhIS7H1WrlwpHx8fhYeHZztuRESELly4oG3bttnb1qxZo4yMDDVs2DCfZou8UFjnjPTnlagmTZqoXr16mj59+g2vlKPoKKxzZtKkSdqxY4d9zO+++06SNHfuXI0ePTofZ4wcKewkhzvfK6+8YtavX2+OHj1qdu7caV555RVjs9nMihUrjDHGfPbZZ2bTpk3m0KFD5vPPPzf+/v5mwIABDseYPHmy2bZtm9m/f7/54IMPjIeHh5k4caJDnypVqjj8V+D58+cbFxcX8+9//9scPHjQTJ482Tg7O5v//ve/+T9p5FphnS8PP/ywqV69ulm7dq05cuSImT59unF3dzcfffRR/k8aee6vq2kZY8xzzz1nypUrZ9asWWO2bt1qIiIiTEREhH3/1atXTY0aNUzLli3N9u3bzbJly0xAQIAZMmSIvc/mzZtNlSpVzKlTp+xtrVq1MnXr1jWbN28233//vQkLCzOdO3cukDkibxXEOXPq1ClTqVIl07x5c3Pq1CkTFxdn33D7Kah/Z/7q6NGjrNpXhBCkkO/++c9/mtDQUOPq6moCAgJM8+bN7b8UG2PM4MGDTVBQkHFxcTFhYWFm3LhxJiMjw+EYXbt2Nf7+/sbV1dXUqlXLzJw5M8s4ksz06dMd2j799FNTqVIl4+7ubmrXrm0WLlyYL3NE3ims8yUuLs50797dhISEGHd3d1OlSpVsj43bw7W/4Fy+fNm88MILpkSJEsbT09M88cQTWX55PXbsmGndurXx8PAwpUqVMgMHDjRpaWn2/WvXrjWSzNGjR+1tv/32m+ncubPx9vY2Pj4+pkePHubixYv5PT3kg4I4Z6ZPn24kZbvh9lNQ/878FUGqaLEZY0yhXAoDAAAAgNsUN+YCAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQCKvO7du+vxxx/P8+PGx8erRYsW8vLykp+fX4GOnR/Kly+vCRMm3LCPzWbTwoULC6QeALiTEaQAAJKKRmA4duyYbDabtm/fXiDjvf/++4qLi9P27dt14MCBbPtMnDhRsbGxBVLPX8XGxl433F3Pli1b1Lt37/wpCADgoFhhFwAAQGE5fPiw6tWrp7CwsOv28fX1LcCKbk1AQEBhlwAAdw2uSAEAcuTXX39V69at5e3traCgIHXt2lX/93//Z9/fpEkTvfjii3r55Zfl7++v4OBgDR8+3OEY+/btU6NGjeTu7q7w8HCtWrXK4VazChUqSJLq1q0rm82mJk2aOLz/vffeU+nSpVWyZEnFxMQoLS3thjVPmTJFFStWlKurq6pUqaLPP//cvq98+fL65ptvNHPmTNlsNnXv3j3bY1x7pS4n87TZbJoyZYpat24tDw8P3Xvvvfr666/t+9etWyebzaYLFy7Y27Zv3y6bzaZjx45p3bp16tGjhxITE2Wz2WSz2bKMkZ1rb+07ePCgGjdubP+8V65c6dA/NTVVffr0UenSpeXu7q7Q0FCNGTPmpuMAAAhSAIAcuHDhgpo1a6a6detq69atWrZsmc6ePasOHTo49JsxY4a8vLy0efNmjR07ViNHjrT/8p6enq7HH39cnp6e2rx5s/7973/r1VdfdXj/Tz/9JElatWqV4uLiNH/+fPu+tWvX6vDhw1q7dq1mzJih2NjYG95yt2DBAvXt21cDBw7Ur7/+qmeffVY9evTQ2rVrJf15G1yrVq3UoUMHxcXFaeLEiTn+PG40z0yvv/662rdvrx07dqhLly7q1KmT9u7dm6PjP/jgg5owYYJ8fHwUFxenuLg4DRo0KMf1SVJGRobatWsnV1dXbd68WVOnTtXgwYMd+kyaNEmLFi3SV199pf3792vWrFkqX768pXEA4G7FrX0AgJv64IMPVLduXb311lv2ts8++0xly5bVgQMHVLlyZUlSrVq1NGzYMElSWFiYPvjgA61evVotWrTQypUrdfjwYa1bt07BwcGSpNGjR6tFixb2Y2bemlayZEl7n0wlSpTQBx98IGdnZ1WtWlXR0dFavXq1nnnmmWxrfu+999S9e3e98MILkqQBAwboxx9/1HvvvaemTZsqICBAbm5u8vDwyDLWzdxonpn+/ve/q1evXpKkN998UytXrtTkyZP10Ucf3fT4rq6u8vX1lc1ms1xbplWrVmnfvn1avny5QkJCJElvvfWWWrdube9z4sQJhYWFqVGjRrLZbAoNDc3VWABwN+KKFADgpnbs2KG1a9fK29vbvlWtWlXSn88ZZapVq5bD+0qXLq2EhARJ0v79+1W2bFmHYHD//ffnuIbq1avL2dk522NnZ+/evXrooYcc2h566KEcXxW6kRvNM1NERESW13kxdk7t3btXZcuWtYeo7Grq3r27tm/fripVqujFF1/UihUrCqw+ALjdcUUKAHBTycnJatu2rd55550s+0qXLm3/s4uLi8M+m82mjIyMPKkhP49d0LU4Of353zGNMfa2mz3vlR/uu+8+HT16VEuXLtWqVavUoUMHRUZGOjzPBQDIHlekAAA3dd9992n37t0qX768KlWq5LB5eXnl6BhVqlTRyZMndfbsWXvbli1bHPq4urpK+vN5qltVrVo1bdy40aFt48aNCg8Pv+Vj58SPP/6Y5XW1atUk/e8Wxri4OPv+a5d8d3V1vaXPoVq1ajp58qTDGNfWJEk+Pj7q2LGjPv74Y82dO1fffPONzp8/n+txAeBuwRUpAIBdYmJill/oM1fI+/jjj9W5c2f7anWHDh3SnDlz9Mknnzjccnc9LVq0UMWKFdWtWzeNHTtWFy9e1GuvvSbpzys6khQYGCgPDw8tW7ZMZcqUkbu7e66XH3/ppZfUoUMH1a1bV5GRkVq8eLHmz5+vVatW5ep4Vs2bN0/169dXo0aNNGvWLP3000/69NNPJUmVKlVS2bJlNXz4cI0ePVoHDhzQuHHjHN5fvnx5JScna/Xq1apdu7Y8PT3l6emZ4/EjIyNVuXJldevWTe+++66SkpKyLO4xfvx4lS5dWnXr1pWTk5PmzZun4OBgy99fBQB3I65IAQDs1q1bp7p16zpsI0aMUEhIiDZu3Kj09HS1bNlSNWvWVL9+/eTn52e/Te1mnJ2dtXDhQiUnJ6tBgwbq1auX/Rd7d3d3SVKxYsU0adIkTZs2TSEhIXrsscdyPZfHH39cEydO1Hvvvafq1atr2rRpmj59epYl1fPLiBEjNGfOHNWqVUszZ87Ul19+ab8a5uLioi+//FL79u1TrVq19M4772jUqFEO73/wwQf13HPPqWPHjgoICNDYsWMtje/k5KQFCxbo8uXLuv/++9WrVy+NHj3aoU/x4sU1duxY1a9fXw0aNNCxY8f03Xff5fhnCgB3M5v56w3aAAAUoI0bN6pRo0Y6dOiQKlasWNjl5BmbzaYFCxY4fP8UAODOwq19AIACs2DBAnl7eyssLEyHDh1S37599dBDD91RIQoAcHcgSAEACszFixc1ePBgnThxQqVKlVJkZGSWZ4OQvf/+978O3wF1reTk5AKsBgDArX0AANwGLl++rNOnT193f6VKlQqwGgAAQQoAAAAALGJZHgAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALPp/BkzAebCGcOYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all of sampels should be the same length\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking how does the base model work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/wzr5897/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1553: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2023-11-19 21:23:18.921114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 21:23:21.888848: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 21:23:27.402512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-19 21:23:27.403362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-19 21:23:27.403389: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does Amazon Virtual Private Cloud (Amazon VPC) allow for the creation and management of a virtual network? # sierpni 2019\n",
      "The 2019 edition of the International Conference on the Future of Europe (FoE) took place in Brussels on 12-13 September. The event was organised by the European Parliament, the European Commission and the European Economic and Social Committee.\n",
      "The conference was attended by over 1,000 participants, including MEPs, representatives of the European Commission, the European Parliament, the European Economic and Social Committee, the European Committee of the Regions, the European Central Bank, the European Investment Bank, the European External Action Service, the European Ombudsman, the European Data Protection Supervisor, the European Court of Auditors, the European Court of Justice, the European Court of Human Rights, the European Network of Ombudsmen for Children, the European Network of Equality Bodies, the European Network of National Human Rights Institutions, the European Network of National Human Rights Institutions, the European Network of Equality Bodies, the European Network of National Human Rights Institutions, the European Network of Equality Bodies, the European Network of National Human Rights Institutions, the European Network of Equality Bodies,\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"How does Amazon Virtual Private Cloud (Amazon VPC) allow for the creation and management of a virtual network? #\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=256, pad_token_id=2)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 81108992 || all params: 3581521920 || trainable%: 2.264651559077991\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32, # . A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "    lora_alpha=64, #a higher value for alpha assigns more weight to the LoRA activations.\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# Apply the accelerator. You can comment this out to remove the accelerator.\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison:\n",
    "* original paper using r=64 and lora_alpha=16 --> trainable params: 162217984 || all params: 3662630912 || trainable%: 4.429001662944519\n",
    "* modified version using r=32 and lora_alpha=64 --> trainable params: 81108992 || all params: 3581521920 || trainable%: 2.264651559077991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (v_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              )\n",
      "              (up_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              )\n",
      "              (down_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=11008, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(\n",
      "        in_features=4096, out_features=32000, bias=False\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model with the LoRA adapters added:\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwenchengzhang2024\u001b[0m (\u001b[33mloranu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login() #you need to register account for weighs and bias, and then you can et the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "#    model.is_parallelizable = True\n",
    "#    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/wzr5897/amazon_lora_llm/wandb/run-20231119_212429-fj5xvfrc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/loranu/journal-finetune/runs/fj5xvfrc' target=\"_blank\">llama2-7b-AmazonVPC-finetune-2023-11-19-21-24</a></strong> to <a href='https://wandb.ai/loranu/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/loranu/journal-finetune' target=\"_blank\">https://wandb.ai/loranu/journal-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/loranu/journal-finetune/runs/fj5xvfrc' target=\"_blank\">https://wandb.ai/loranu/journal-finetune/runs/fj5xvfrc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 2:00:42, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.716249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.659833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.640206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.624117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.637507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.632669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.626271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.662743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.661569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.415000</td>\n",
       "      <td>1.686076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=1.415006591796875, metrics={'train_runtime': 7254.323, 'train_samples_per_second': 0.138, 'train_steps_per_second': 0.069, 'total_flos': 1.59880771141632e+16, 'train_loss': 1.415006591796875, 'epoch': 4.31})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"AmazonVPC-finetune\"\n",
    "base_model_name = \"llama2-7b\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        #bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=50,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=50,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
